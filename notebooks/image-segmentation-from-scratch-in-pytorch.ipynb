{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud segmentation in python\n",
    "\n",
    "There are several great notebooks to build on. For educational purposes, a nice way to learn about image segmentation is to use a [kernel starting from scratch](https://www.kaggle.com/code/dhananjay3/image-segmentation-from-scratch-in-pytorch), understand the architecture and then improve by borrowing other elements from other NBs.\n",
    "Another pitfall to avoid while learning is to use high-level frameworks, convenient for prototyping but not for learning, as they may hide all the details\n",
    "\n",
    "## Features of this NB\n",
    "* Using the Unet Architecture\n",
    "* Deterministic behaviour for reproducibility\n",
    "* K-fold cross-validation \n",
    "* Implement the loss function for clarity, as done in the python package [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch)\n",
    "* Investigation of the training process\n",
    "* Processing output (removing the mask that occurs on the black part of the input image)\n",
    "* Drawing convex hull before optimizing thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet architecture\n",
    "![Unet](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **references**\n",
    "1. https://www.kaggle.com/code/dhananjay3/image-segmentation-from-scratch-in-pytorch\n",
    "2. https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools\n",
    "3. https://www.kaggle.com/ryches/turbo-charging-andrew-s-pytorch\n",
    "4. https://github.com/qubvel/segmentation_models.pytorch/blob/master/segmentation_models_pytorch/utils/losses.py\n",
    "5. https://github.com/milesial/Pytorch-UNet\n",
    "6. https://www.kaggle.com/ratthachat/cloud-convexhull-polygon-postprocessing-no-gpu\n",
    "7. https://github.com/qubvel/segmentation_models.pytorch\n",
    "8. https://github.com/albumentations-team/albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm as tq\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "# ablumentations for easy image augmentation for input as well as output\n",
    "import albumentations as albu\n",
    "# from albumentations import torch as AT\n",
    "\n",
    "# Custom package for the project, save all the functions into appropriate sub-packages\n",
    "from pyreidolia.plot import set_my_plt_style, plot_cloud, plot_rnd_cloud, draw_label_only\n",
    "from pyreidolia.mask import bounding_box, rle_to_mask, get_binary_mask_sum\n",
    "from pyreidolia.img import get_resolution_sharpness\n",
    "from pyreidolia.processing import resize, draw_convex_hull, post_process\n",
    "\n",
    "from pyreidolia.unet import UNet\n",
    "from pyreidolia.optim import RAdam\n",
    "from pyreidolia.io import get_img\n",
    "from pyreidolia.segmentation import seed_everything, to_tensor, CloudDataset, get_training_augmentation, get_validation_augmentation, dice_no_threshold, BCEDiceLoss\n",
    "\n",
    "set_my_plt_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "class_names = ['Fish', 'Flower', 'Sugar', 'Gravel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "where is the paths.yml config file? C:/Users/xtbury/Documents/Projects/Pyreidolia/paths.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'docs': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/data/',\n",
      "          'test': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/data/test_images/',\n",
      "          'train': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/data/train_images/'},\n",
      " 'notebooks': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/notebooks/',\n",
      " 'output': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/output/',\n",
      " 'reports': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/reports/',\n",
      " 'scripts': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/scripts/',\n",
      " 'studies': 'C:/Users/xtbury/Documents/Projects/Pyreidolia/studies/'}\n"
     ]
    }
   ],
   "source": [
    "# Where is my yaml ? \"C:/Users/xtbury/Documents/Projects/Pyreidolia/paths.yml\"\n",
    "\n",
    "paths_yml = input(\"where is the paths.yml config file?\")\n",
    "with open(paths_yml, \"r\") as ymlfile:\n",
    "    path_dic = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "pprint(path_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be trained on GPU: False\n"
     ]
    }
   ],
   "source": [
    "# path = \"../input/understanding_cloud_organization\"\n",
    "# img_paths = \"../input/understanding-clouds-resized\"\n",
    "# os.listdir(path)\n",
    "train_on_gpu = torch.cuda.is_available() GPU memory too small\n",
    "print(f\"The model will be trained on GPU: {train_on_gpu}\")\n",
    "SEED = 42\n",
    "MODEL_NO = 0 # in K-fold\n",
    "N_FOLDS = 10 # in K-fold\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make split in train test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set   ['0011165.jpg' '002be4f.jpg' '0031ae9.jpg' '0035239.jpg' '003994e.jpg'].. with length 4991\n",
      "validation set ['00498ec.jpg' '006bf7c.jpg' '008a5ff.jpg' '0146ef3.jpg' '01eecc1.jpg'].. with length 555\n",
      "testing set    ['002f507.jpg' '0035ae9.jpg' '0038327.jpg' '004f759.jpg' '005ba08.jpg'].. with length 3698\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = path_dic['data']['docs'] + 'train.csv'\n",
    "\n",
    "train = pd.read_csv(train_csv_path)\n",
    "train[\"label\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[1])\n",
    "train[\"im_id\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "sub = pd.read_csv(path_dic['data']['docs'] + \"sample_submission.csv\")\n",
    "sub[\"label\"] = sub[\"Image_Label\"].apply(lambda x: x.split(\"_\")[1])\n",
    "sub[\"im_id\"] = sub[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "# split data\n",
    "id_mask_count = (\n",
    "    train.loc[train[\"EncodedPixels\"].isnull() == False, \"Image_Label\"]\n",
    "    .apply(lambda x: x.split(\"_\")[0])\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"img_id\", \"Image_Label\": \"count\"})\n",
    ")\n",
    "ids = id_mask_count[\"img_id\"].values\n",
    "li = [\n",
    "    [train_index, test_index]\n",
    "    for train_index, test_index in StratifiedKFold(\n",
    "        n_splits=N_FOLDS, random_state=SEED, shuffle=True,\n",
    "    ).split(ids, id_mask_count[\"count\"])\n",
    "]\n",
    "train_ids, valid_ids = ids[li[MODEL_NO][0]], ids[li[MODEL_NO][1]]\n",
    "test_ids = sub[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0]).drop_duplicates().values\n",
    "\n",
    "print(f\"training set   {train_ids[:5]}.. with length {len(train_ids)}\")\n",
    "print(f\"validation set {valid_ids[:5]}.. with length {len(valid_ids)}\")\n",
    "print(f\"testing set    {test_ids[:5]}.. with length {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/xtbury/Documents/Projects/Pyreidolia/data/train_images/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dic['data']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset and dataloader\n",
    "num_workers = 2\n",
    "bs = 8\n",
    "train_dataset = CloudDataset(\n",
    "    df=train,\n",
    "    datatype=\"train\",\n",
    "    img_ids=train_ids,\n",
    "    img_dir=path_dic['data']['train'],\n",
    "    subfolder=\"train_images_525/\",\n",
    "    transforms=get_training_augmentation(),\n",
    ")\n",
    "valid_dataset = CloudDataset(\n",
    "    df=train,\n",
    "    datatype=\"valid\",\n",
    "    img_ids=valid_ids,\n",
    "    img_dir=path_dic['data']['train'],\n",
    "    subfolder=\"train_images_525/\",\n",
    "    transforms=get_validation_augmentation(),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=3, n_classes=4).float()\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): inconv(\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down1): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): up(\n",
       "    (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): up(\n",
       "    (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): up(\n",
       "    (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): up(\n",
       "    (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): outconv(\n",
       "    (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCEDiceLoss(eps=1.0, activation=None)\n",
    "optimizer = RAdam(model.parameters(), lr = 0.005)\n",
    "current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=2, cooldown=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5d9e1257bd4b8ca00e5e72437c27e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:10<?, ?it/s, train_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xtbury\\documents\\projects\\pyreidolia\\pyreidolia\\optim.py:57: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\python_arg_parser.cpp:1055.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9107f5622f6d42bb97734aa223561ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:13<?, ?it/s, dice_score=0, valid_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Training Loss: 1.064907  Validation Loss: 1.001117 Dice Score: 0.000000\n",
      "Validation loss decreased (inf --> 1.001117).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fb630d6c474cf5b626a7723695651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:10<?, ?it/s, train_loss=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 32\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "dice_score_list = []\n",
    "lr_rate_list = []\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    dice_score = 0.0\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    bar = tq(train_loader, postfix={\"train_loss\":0.0})\n",
    "    for data, target in bar:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        #print(loss)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        bar.set_postfix(ordered_dict={\"train_loss\":loss.item()})\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    del data, target\n",
    "    with torch.no_grad():\n",
    "        bar = tq(valid_loader, postfix={\"valid_loss\":0.0, \"dice_score\":0.0})\n",
    "        for data, target in bar:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            dice_cof = dice_no_threshold(output.cpu(), target.cpu()).item()\n",
    "            dice_score +=  dice_cof * data.size(0)\n",
    "            bar.set_postfix(ordered_dict={\"valid_loss\":loss.item(), \"dice_score\":dice_cof})\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    dice_score = dice_score/len(valid_loader.dataset)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    dice_score_list.append(dice_score)\n",
    "    lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {}  Training Loss: {:.6f}  Validation Loss: {:.6f} Dice Score: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss, dice_score))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "    \n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot([i[0] for i in lr_rate_list])\n",
    "plt.ylabel('learing rate during training', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\n",
    "plt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\n",
    "plt.ylabel('loss', fontsize=22)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(dice_score_list)\n",
    "plt.ylabel('Dice score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.load_state_dict(torch.load('model_cifar.pt'))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_masks = []\n",
    "count = 0\n",
    "tr = min(len(valid_ids)*4, 2000)\n",
    "probabilities = np.zeros((tr, 350, 525), dtype = np.float32)\n",
    "for data, target in tq(valid_loader):\n",
    "    if train_on_gpu:\n",
    "        data = data.cuda()\n",
    "    target = target.cpu().detach().numpy()\n",
    "    outpu = model(data).cpu().detach().numpy()\n",
    "    for p in range(data.shape[0]):\n",
    "        output, mask = outpu[p], target[p]\n",
    "        for m in mask:\n",
    "            valid_masks.append(resize(m))\n",
    "        for probability in output:\n",
    "            probabilities[count, :, :] = resize(probability)\n",
    "            count += 1\n",
    "        if count >= tr - 1:\n",
    "            break\n",
    "    if count >= tr - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for best Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_params = {}\n",
    "for class_id in range(4):\n",
    "    print(class_id)\n",
    "    attempts = []\n",
    "    for t in range(0, 100, 5):\n",
    "        t /= 100\n",
    "        for ms in [0, 100, 1200, 5000, 10000, 30000]:\n",
    "            masks, d = [], []\n",
    "            for i in range(class_id, len(probabilities), 4):\n",
    "                probability = probabilities[i]\n",
    "                predict, num_predict = post_process(probability, t, ms)\n",
    "                masks.append(predict)\n",
    "            for i, j in zip(masks, valid_masks[class_id::4]):\n",
    "                if (i.sum() == 0) & (j.sum() == 0):\n",
    "                    d.append(1)\n",
    "                else:\n",
    "                    d.append(dice(i, j))\n",
    "            attempts.append((t, ms, np.mean(d)))\n",
    "\n",
    "    attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
    "    attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
    "    print(attempts_df.head())\n",
    "    best_threshold = attempts_df['threshold'].values[0]\n",
    "    best_size = attempts_df['size'].values[0]\n",
    "    class_params[class_id] = (best_threshold, best_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del masks\n",
    "del valid_masks\n",
    "del probabilities\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
    "print(class_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts_df.groupby(['threshold'])['dice'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts_df.groupby(['size'])['dice'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
    "attempts_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='threshold', y='dice', hue='size', data=attempts_df);\n",
    "plt.title('Threshold and min size vs dice');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = attempts_df['threshold'].values[0]\n",
    "best_size = attempts_df['size'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, target) in enumerate(valid_loader):\n",
    "    if train_on_gpu:\n",
    "        data = data.cuda()\n",
    "    output = ((model(data))[0]).cpu().detach().numpy()\n",
    "    image  = data[0].cpu().detach().numpy()\n",
    "    mask   = target[0].cpu().detach().numpy()\n",
    "    output = output.transpose(1 ,2, 0)\n",
    "    image_vis = image.transpose(1, 2, 0)\n",
    "    mask = mask.astype('uint8').transpose(1, 2, 0)\n",
    "    pr_mask = np.zeros((350, 525, 4))\n",
    "    for j in range(4):\n",
    "        probability = resize(output[:, :, j])\n",
    "        pr_mask[:, :, j], _ = post_process(probability,\n",
    "                                           class_params[j][0],\n",
    "                                           class_params[j][1])\n",
    "    visualize_with_raw(image=image_vis, mask=pr_mask,\n",
    "                      original_image=image_vis, original_mask=mask,\n",
    "                      raw_image=image_vis, raw_mask=output)\n",
    "    if i >= 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CloudDataset(df=sub,\n",
    "                            datatype='test', \n",
    "                            img_ids=test_ids,\n",
    "                            transforms=get_validation_augmentation())\n",
    "test_loader = DataLoader(test_dataset, batch_size=4,\n",
    "                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset, train_loader\n",
    "del valid_dataset, valid_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv(\"../input/understanding_cloud_organization/sample_submission.csv\")\n",
    "pathlist = [\"../input/understanding_cloud_organization/test_images/\" + i.split(\"_\")[0] for i in subm['Image_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_mask(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (525,350))\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 0, 0], np.uint8)\n",
    "    upper = np.array([180, 255, 10], np.uint8)\n",
    "    return (~ (cv2.inRange(hsv, lower, upper) > 250)).astype(int)\n",
    "\n",
    "plt.imshow(get_black_mask(pathlist[120]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_pixels = []\n",
    "image_id = 0\n",
    "cou = 0\n",
    "np_saved = 0\n",
    "for data, target in tq(test_loader):\n",
    "    if train_on_gpu:\n",
    "        data = data.cuda()\n",
    "    output = model(data)\n",
    "    del data\n",
    "    for i, batch in enumerate(output):\n",
    "        for probability in batch:\n",
    "            probability = resize(probability.cpu().detach().numpy())\n",
    "            predict, num_predict = post_process(probability,\n",
    "                                                class_params[image_id % 4][0],\n",
    "                                                class_params[image_id % 4][1])\n",
    "            if num_predict == 0:\n",
    "                encoded_pixels.append('')\n",
    "            else:\n",
    "                black_mask = get_black_mask(pathlist[cou])\n",
    "                np_saved += np.sum(predict)\n",
    "                predict = np.multiply(predict, black_mask)\n",
    "                np_saved -= np.sum(predict)\n",
    "                r = mask_to_rle(predict)\n",
    "                encoded_pixels.append(r)\n",
    "            cou += 1\n",
    "            image_id += 1\n",
    "\n",
    "print(f\"number of pixel saved {np_saved}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['EncodedPixels'] = encoded_pixels\n",
    "sub.to_csv('submission.csv', columns=['Image_Label', 'EncodedPixels'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cloudseg]",
   "language": "python",
   "name": "conda-env-cloudseg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
