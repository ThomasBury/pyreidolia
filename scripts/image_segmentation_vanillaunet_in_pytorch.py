# -*- coding: utf-8 -*-
"""image-segmentation-vanillaUNet-in-pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KvIJPPWT4odZ-bVhODkYRCsGGa0j-jJk

<h1 align="center">☁️ - Cloudy regions segmentation 👨‍💻🔬</h1>

<h2 align="center">Segmentation - Vanilla UNet in Pytorch</h2>
<p align="center">
   Thomas Bury, Afonso Alves, Daniel Staudegger<br>
</p>

## Introduction

There are several great notebooks to build on. For educational purposes, a nice way to learn about image segmentation is to use a [kernel starting from scratch](https://www.kaggle.com/code/dhananjay3/image-segmentation-from-scratch-in-pytorch), understand the architecture and then improve by borrowing other elements from other NBs.
Another pitfall to avoid while learning is to use high-level frameworks, convenient for prototyping but not for learning, as they may hide all the details

## Why instance segmentation?
Many deep network architectures are dedicated to classification. However, when localization is also required, we need a pixel-to-pixel identification and a label prediction. Here is the qualitative difference with other methods

![inst_seg](https://i.stack.imgur.com/MEB9F.png)

## Features of this NB
* Using the Unet Architecture
* Deterministic behaviour for reproducibility
* K-fold cross-validation 
* Implement the loss function for clarity, as done in the python package [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch)
* Investigation of the training process
* Processing output (removing the mask that occurs on the black part of the input image)
* Drawing convex hull before optimizing thresholds

## Unet architecture

U-net architecture (example for 32x32 pixels in the lowest resolution). Each blue box corresponds to a multi-channel feature map. The number of channels is denoted on top of the box. The x-y-size is provided at the lower left edge of the box. White boxes represent copied feature maps. The arrows denote the different operations. 

The architecture consists of a contracting path to capture
context and a symmetric expanding path that enables precise localization. Such a network outperforms the prior best method (a sliding-window
convolutional network) on medical images. One important feature in the UNet architecture is that in the upsampling part there is also a large number of feature channels, which allow the network to propagate context information to higher resolution layers. As a consequence, the expansive path is more or less symmetric to the contracting path, and yields a u-shaped architecture (hence the name).

 * The contracting path follows the scheme `conv_layer1 -> conv_layer2 -> max_pooling -> dropout(optional)`, meaning feature extraction, downsampling (feature selection/dim reduction) and regularization (dropout).
 * The bottom part is only convulotional steps, feature extraction
 * The expansive path follows the scheme `conv_2d_transpose -> concatenate -> conv_layer1 -> conv_layer2` Transposed convolution is an upsampling method that expands the size of images (set the value of a pixel from the kernel to n pixels of the target array). See [the visual explanation](https://naokishibuya.medium.com/up-sampling-with-transposed-convolution-9ae4f2df52d0).

Details in a [short video](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) made by the authors of [the original paper](https://arxiv.org/pdf/1505.04597.pdf)

![Unet](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)

### **references**
1. https://www.kaggle.com/code/dhananjay3/image-segmentation-from-scratch-in-pytorch
2. https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools
3. https://www.kaggle.com/ryches/turbo-charging-andrew-s-pytorch
4. https://github.com/qubvel/segmentation_models.pytorch/blob/master/segmentation_models_pytorch/utils/losses.py
5. https://github.com/milesial/Pytorch-UNet
6. https://www.kaggle.com/ratthachat/cloud-convexhull-polygon-postprocessing-no-gpu
7. https://github.com/qubvel/segmentation_models.pytorch
8. https://github.com/albumentations-team/albumentations
"""

!pip uninstall pyreidolia

!pip install -U git+https://github.com/ThomasBury/pyreidolia

"""# Imports"""

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.optim import lr_scheduler
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data import TensorDataset, DataLoader, Dataset
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau

# ablumentations for easy image augmentation for input as well as output
import albumentations as albu
# from albumentations import torch as AT
from zipfile import ZipFile
import os
import gc
import cv2
import time
import tqdm
import random
import collections
import numpy as np
import pandas as pd
import seaborn as sns
from PIL import Image
from functools import partial
import matplotlib.pyplot as plt
from tqdm.auto import tqdm as tq
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
import yaml
from pprint import pprint

# Custom package for the project, save all the functions into appropriate sub-packages
from pyreidolia.plot import (set_my_plt_style, 
                             plot_cloud, 
                             plot_rnd_cloud, 
                             draw_label_only, 
                             visualize_with_raw)
from pyreidolia.mask import (bounding_box, 
                             rle_to_mask, 
                             get_binary_mask_sum, 
                             mask_to_rle)
from pyreidolia.img import get_resolution_sharpness
from pyreidolia.processing import resize, draw_convex_hull, post_process

from pyreidolia.unet import UNet
from pyreidolia.optim import RAdam
from pyreidolia.io import get_img
from pyreidolia.segmentation import (seed_everything, 
                                     to_tensor, 
                                     CloudDataset, 
                                     get_training_augmentation, 
                                     get_validation_augmentation, 
                                     dice_no_threshold, 
                                     dice,
                                     BCEDiceLoss)

set_my_plt_style()

import scicomap as sc
import matplotlib as mpl
sc_map = sc.ScicoSequential(cmap='eclipse')
sc_map.unif_sym_cmap(lift=None, 
                     bitonic=False, 
                     diffuse=True)
sc_cmap = sc_map.get_mpl_color_map()

mpl.cm.register_cmap("sc_eclipse", sc_cmap)

# with ZipFile('/content/test_images_525.zip', 'r') as zipObj:
#    # Extract all the contents of zip file in current directory
#    zipObj.extractall()

# from google.colab import files
# uploaded = files.upload()

# from google.colab import drive
# drive.mount('/content/drive') #, force_remount=True)

# doc_path = "/content/drive/MyDrive/pyreidolia/train.csv"
# doc_clean_path = "/content/drive/MyDrive/pyreidolia/train_info_clean.csv"
# submission_path = "/content/drive/MyDrive/pyreidolia/sample_submission.csv"
# folder_path = "/content/drive/MyDrive/pyreidolia/"
# train_path =  "/content/drive/MyDrive/pyreidolia/train_images_525/"
# mask_path = "/content/drive/MyDrive/pyreidolia/train_masks_525/"
# test_path = "/content/drive/MyDrive/pyreidolia/test_images_525/"


doc_path = "/content/train.csv"
doc_clean_path = "/content/train_info_clean.csv"
submission_path = "/content/sample_submission.csv"
folder_path = "/content/"
train_path =  "/content/train_images_525/"
mask_path = "/content/train_masks_525/"
test_path = "/content/test_images_525/"

"""# Helper functions"""

# helper functions
class_names = ['Fish', 'Flower', 'Sugar', 'Gravel']

# sigmoid = lambda x: 1 / (1 + np.exp(-x))
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Where is my yaml ? "C:/Users/xtbury/Documents/Projects/Pyreidolia/paths.yml"

# paths_yml = input("where is the paths.yml config file?")
# with open(paths_yml, "r") as ymlfile:
#     path_dic = yaml.load(ymlfile, Loader=yaml.FullLoader)

# pprint(path_dic)

# path = "../input/understanding_cloud_organization"
# img_paths = "../input/understanding-clouds-resized"
# os.listdir(path)
train_on_gpu = torch.cuda.is_available()
print(f"The model will be trained on GPU: {train_on_gpu}")
SEED = 42
MODEL_NO = 0 # in K-fold
N_FOLDS = 3 # in K-fold
seed_everything(SEED)

"""## Make split in train test validation

We can also filter out all the images with poor quality, usually having either a big black band or a bright band (or both).
"""

train = pd.read_parquet('/content/train_info_clean.parquet')
train.shape

ax = train.sharpness.hist(bins=50)
ax.axvline(x=train.sharpness.median(), color='r');
ax.axvline(x=train.sharpness.quantile(.25), color='k');
print(f"The sharpness threshold {train.sharpness.quantile(.25):.2f}")

img_id_list = list(train.loc[train.sharpness >= 23.0, 'image_id'])
img = cv2.imread(train_path + img_id_list[0])
plt.title("Good quality image")
plt.imshow(img);

very_bad_img_id_list = list(train.loc[train.sharpness < 13.0, 'image_id'])
img = cv2.imread(train_path + very_bad_img_id_list[1])
plt.title("Poor quality image")
plt.imshow(img);

# read the original documentation
train = pd.read_csv('/content/train.zip')
train.shape

train["label"] = train["Image_Label"].apply(lambda x: x.split("_")[1])
train["im_id"] = train["Image_Label"].apply(lambda x: x.split("_")[0])

# only good images are used
train = train.loc[train["im_id"].isin(img_id_list), :]

sub = pd.read_csv(submission_path)
sub["label"] = sub["Image_Label"].apply(lambda x: x.split("_")[1])
sub["im_id"] = sub["Image_Label"].apply(lambda x: x.split("_")[0])

# split data
id_mask_count = (
    train.loc[train["EncodedPixels"].isnull() == False, "Image_Label"]
    .apply(lambda x: x.split("_")[0])
    .value_counts()
    .sort_index()
    .reset_index()
    .rename(columns={"index": "img_id", "Image_Label": "count"})
)
ids = id_mask_count["img_id"].values
li = [
    [train_index, test_index]
    for train_index, test_index in StratifiedKFold(
        n_splits=N_FOLDS, random_state=SEED, shuffle=True,
    ).split(ids, id_mask_count["count"])
]
train_ids, valid_ids = ids[li[MODEL_NO][0]], ids[li[MODEL_NO][1]]
test_ids = sub["Image_Label"].apply(lambda x: x.split("_")[0]).drop_duplicates().values

print(f"training set   {train_ids[:5]}.. with length {len(train_ids)}")
print(f"validation set {valid_ids[:5]}.. with length {len(valid_ids)}")
print(f"testing set    {test_ids[:5]}.. with length {len(test_ids)}")

"""## Define the data-loader
The data-loaders will push the images to the GPU while augmenting the data (new images) by performing transformations (rotation, crop, etc.)

"""

# define dataset and dataloader
num_workers = 0 # to avoid any parallelization error, set this to 0
bs = 8
train_dataset = CloudDataset(
    df=train,
    datatype="train",
    img_ids=train_ids,
    img_dir=folder_path,
    subfolder = "train_images_525/",
    mask_subfolder = "train_masks_525/",
    transforms=get_training_augmentation(),
)
valid_dataset = CloudDataset(
    df=train,
    datatype="valid",
    img_ids=valid_ids,
    img_dir=folder_path,
    subfolder = "train_images_525/",
    mask_subfolder = "train_masks_525/",
    transforms=get_validation_augmentation(),
)

train_loader = DataLoader(
    train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers
)
valid_loader = DataLoader(
    valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers
)

"""## Model definition and set up

In this first attempt, the native (vanilla) UNet architecture is used.
"""

# one channel because images converted to grayscale
model = UNet(n_channels=3, n_classes=4).float()
if train_on_gpu:
    model.cuda()

model # print Model

"""## Model set up
We define the 
* loss function (weighted average of thebinary cross-entropy and the dice coefficient)
* the optimizer: rectified Adam (less sensitive to the learning rate)
* update of the learning rate (for finer optimization, but takes longer)
* learning rate updater
"""

criterion = BCEDiceLoss(eps=1.0, activation=None)
optimizer = RAdam(model.parameters(), lr = 0.005)
current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=2, cooldown=2)

"""## Training loop
The usual training loop, without fancy add-ons

 - push to gpu
 - forward pass : compute the predicted outputs
 - compute the loss
 - backward propagation : compute the gradient of the loss w.r.t the models parameters
 - perform a step of parameters optimization

Evalutate on the validation set and iterate for several cycles (aka epochs). Save the best model. 
"""

# number of epochs to train the model
n_epochs = 32
train_loss_list = []
valid_loss_list = []
dice_score_list = []
lr_rate_list = []
valid_loss_min = np.Inf # track change in validation loss
epoch_bar = tq(range(1, n_epochs+1))
for epoch in epoch_bar:
    epoch_bar.set_description(f"Epoch {epoch:<4}")
    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0
    dice_score = 0.0
    ###################
    # train the model #
    ###################
    model.train()
    bar = tq(train_loader, postfix={"train_loss":0.0})
    batch_nbr = 0
    for data, target in bar:
        bar.set_description(f"Training on batch {batch_nbr:<4}")
        batch_nbr += 1
        # move tensors to GPU if CUDA is available
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        # clear the gradients of all optimized variables
        optimizer.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = model(data)
        # calculate the batch loss
        loss = criterion(output, target)
        #print(loss)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer.step()
        # update training loss
        train_loss += loss.item()*data.size(0)
        bar.set_postfix(ordered_dict={"train_loss":loss.item()})
    ######################    
    # validate the model #
    ######################
    model.eval()
    del data, target
    with torch.no_grad():
        bar = tq(valid_loader, postfix={"valid_loss":0.0, "dice_score":0.0}, desc='validation')
        for data, target in bar:
            # move tensors to GPU if CUDA is available
            if train_on_gpu:
                data, target = data.cuda(), target.cuda()
            # forward pass: compute predicted outputs by passing inputs to the model
            output = model(data)
            # calculate the batch loss
            loss = criterion(output, target)
            # update average validation loss 
            valid_loss += loss.item()*data.size(0)
            dice_cof = dice_no_threshold(output.cpu(), target.cpu()).item()
            dice_score +=  dice_cof * data.size(0)
            bar.set_postfix(ordered_dict={"valid_loss":loss.item(), "dice_score":dice_cof})
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.dataset)
    valid_loss = valid_loss/len(valid_loader.dataset)
    dice_score = dice_score/len(valid_loader.dataset)
    train_loss_list.append(train_loss)
    valid_loss_list.append(valid_loss)
    dice_score_list.append(dice_score)
    lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])
    
    # print training/validation statistics 
    print(f'Epoch: {epoch}  Training Loss: {train_loss:.6f}  Validation Loss: {valid_loss:.6f} Dice Score: {dice_score:.6f}')
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), folder_path + 'vanilla_unet.pt')
        valid_loss_min = valid_loss
    
    scheduler.step(valid_loss)

"""## Ploting Metrics"""

plt.figure(figsize=(5,5))
plt.plot([i[0] for i in lr_rate_list])
plt.ylabel('learing rate during training', fontsize=22)
plt.show()

plt.figure(figsize=(5,5))
plt.plot(train_loss_list,  marker='o', label="Training Loss")
plt.plot(valid_loss_list,  marker='o', label="Validation Loss")
plt.ylabel('loss', fontsize=22)
plt.legend()
plt.show()

plt.figure(figsize=(5,5))
plt.plot(dice_score_list)
plt.ylabel('Dice score')
plt.show()

# load best model
model.load_state_dict(torch.load(folder_path + 'vanilla_unet.pt'))
model.eval();

valid_masks = []
count = 0
tr = min(len(valid_ids)*4, 2000)
probabilities = np.zeros((tr, 350, 525), dtype = np.float32)
valid_bar = tq(valid_loader)
val_batch_nbr = 0
for data, target in valid_bar:
    valid_bar.set_description(f"Validating on batch nbr {val_batch_nbr:4}")
    val_batch_nbr += 1
    if train_on_gpu:
        data = data.cuda()
    target = target.cpu().detach().numpy()
    outpu = model(data).cpu().detach().numpy()
    for p in range(data.shape[0]):
        output, mask = outpu[p], target[p]
        for m in mask:
            valid_masks.append(resize(m))
        for probability in output:
            probabilities[count, :, :] = resize(probability)
            count += 1
        if count >= tr - 1:
            break
    if count >= tr - 1:
        break

valid_masks = []
count = 0
tr = min(len(valid_ids)*4, 2000)
probabilities = np.zeros((tr, 350, 525), dtype = np.float32)
val_batch_nbr = 0
for data, target in valid_bar:
    valid_bar.set_description(f"Validating on batch nbr {val_batch_nbr:4}")
    val_batch_nbr += 1
    if train_on_gpu:
        data = data.cuda()
    target = target.cpu().detach().numpy()
    outpu = model(data).cpu().detach().numpy()
    for p in range(data.shape[0]):
        output, mask = outpu[p], target[p]
        for m in mask:
            valid_masks.append(resize(m))
        for probability in output:
            probabilities[count, :, :] = resize(probability)
            count += 1
        if count >= tr - 1:
            break
    if count >= tr - 1:
        break

"""## Grid Search for best Threshold
Try out several threshold for the probability, compute the loss and choose the best value (validation set)
"""

class_params = {}
for class_id in range(4):
    print(class_id)
    attempts = []
    for t in range(0, 100, 5):
        t /= 100
        for ms in [0, 100, 1200, 5000, 10000, 30000]:
            masks, d = [], []
            for i in range(class_id, len(probabilities), 4):
                probability = probabilities[i]
                predict, num_predict = post_process(probability, t, ms)
                masks.append(predict)
            for i, j in zip(masks, valid_masks[class_id::4]):
                if (i.sum() == 0) & (j.sum() == 0):
                    d.append(1)
                else:
                    d.append(dice(i, j))
            attempts.append((t, ms, np.mean(d)))

    attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])
    attempts_df = attempts_df.sort_values('dice', ascending=False)
    print(attempts_df.head())
    best_threshold = attempts_df['threshold'].values[0]
    best_size = attempts_df['size'].values[0]
    class_params[class_id] = (best_threshold, best_size)

del masks
del valid_masks
del probabilities
gc.collect()

attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])
print(class_params)

attempts_df.groupby(['threshold'])['dice'].max()

attempts_df.groupby(['size'])['dice'].max()

attempts_df = attempts_df.sort_values('dice', ascending=False)
attempts_df.head(10)

attempts_df.to_csv("grid_search_thres.csv")

sc_map = sc.ScicoQualitative(cmap='colorblind')
sc_cmap = sc_map.get_mpl_color_map()
mpl.cm.register_cmap("sc_cb", sc_cmap)

sc_cmap

attempts_df = pd.read_csv('grid_search_thres.csv', index_col=0)
attempts_df.info()

fig, ax = plt.subplots(figsize=(6, 4))
attempts_df['size'] = attempts_df['size'].astype("category")
ax = sns.lineplot(x='threshold', 
                   y='dice',
                   data=attempts_df, 
                   hue='size', 
                   palette='sc_cb', 
                   ax=ax)
ax.set_title('Threshold and min size vs dice');
fig.savefig("gridsearch_thres.png")

best_threshold = attempts_df['threshold'].values[0]
best_size = attempts_df['size'].values[0]

"""## Predictions visualization
Qualitative visualization of the prediction: original image and mask, probabilities, thresholded probabilities and the convex hull of the detected regions.
"""

for i, (data, target) in enumerate(valid_loader):
    if train_on_gpu:
        data = data.cuda()
    output = ((model(data))[0]).cpu().detach().numpy()
    image  = data[0].cpu().detach().numpy()
    mask   = target[0].cpu().detach().numpy()
    output = output.transpose(1 ,2, 0)
    image_vis = image.transpose(1, 2, 0)
    mask = mask.astype('uint8').transpose(1, 2, 0)
    pr_mask = np.zeros((350, 525, 4))
    for j in range(4):
        probability = resize(output[:, :, j])
        pr_mask[:, :, j], _ = post_process(probability,
                                           class_params[j][0],
                                           class_params[j][1])
    visualize_with_raw(image=image_vis, mask=pr_mask,
                      original_image=image_vis, original_mask=mask,
                      raw_image=image_vis, raw_mask=output)
    if i >= 6:
        break

torch.cuda.empty_cache()
gc.collect()

test_dataset = CloudDataset(df=sub,
                            datatype='test', 
                            img_ids=test_ids,
                            img_dir=folder_path,
                            subfolder = "test_images_525/",
                            mask_subfolder = "train_masks_525/",
                            transforms=get_validation_augmentation())
test_loader = DataLoader(test_dataset, 
                         batch_size=4,
                         shuffle=False, 
                         num_workers=2)

del train_dataset, train_loader
del valid_dataset, valid_loader
gc.collect()

"""## Compute scores on the test set"""

subm = pd.read_csv(submission_path)
pathlist = [test_path + i.split("_")[0] for i in subm['Image_Label']]

def get_black_mask(image_path):
    img = cv2.imread(image_path) 
    img = cv2.resize(img, dsize=tuple((525,350)), interpolation=cv2.INTER_LINEAR)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower = np.array([0, 0, 0], np.uint8)
    upper = np.array([180, 255, 10], np.uint8)
    return (~ (cv2.inRange(hsv, lower, upper) > 250)).astype(int)

plt.imshow(get_black_mask(pathlist[120]))
plt.show();

encoded_pixels = []
image_id = 0
cou = 0
np_saved = 0
for data, target in tq(test_loader):
    if train_on_gpu:
        data = data.cuda()
    output = model(data)
    del data
    for i, batch in enumerate(output):
        for probability in batch:
            probability = resize(probability.cpu().detach().numpy())
            predict, num_predict = post_process(probability,
                                                class_params[image_id % 4][0],
                                                class_params[image_id % 4][1])
            if num_predict == 0:
                encoded_pixels.append('')
            else:
                black_mask = get_black_mask(pathlist[cou])
                np_saved += np.sum(predict)
                predict = np.multiply(predict, black_mask)
                np_saved -= np.sum(predict)
                r = mask_to_rle(predict)
                encoded_pixels.append(r)
            cou += 1
            image_id += 1

print(f"number of pixel saved {np_saved}")

sub['EncodedPixels'] = encoded_pixels
sub.to_csv('unet_vanilla_pred_test.csv', columns=['Image_Label', 'EncodedPixels'], index=False)